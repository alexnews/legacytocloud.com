# Session Log - December 25, 2025

## Summary
Added SEO landing pages for MariaDB and Aurora migrations, implemented schema file upload feature with Snowflake DDL generation.

---

## Part 1: SEO Landing Pages

### Created New Migration Pages
- `/mariadb-to-snowflake` - MariaDB to Snowflake migration page
- `/aurora-to-snowflake` - Amazon Aurora (MySQL/PostgreSQL) to Snowflake page

### Features:
- Type mapping tables
- Migration process steps
- MariaDB-specific considerations (sequences, system-versioned tables, virtual columns)
- Aurora dual-flavor support (MySQL and PostgreSQL)
- Share buttons, CTAs

### Updated Footer Navigation
All pages now include links to all 5 migration paths:
- MSSQL to Snowflake
- MySQL to Snowflake
- PostgreSQL to Snowflake
- MariaDB to Snowflake
- Aurora to Snowflake

---

## Part 2: Deploy Script

Updated `deploy.sh` with flexible options:

```bash
./deploy.sh           # Deploy both backend and frontend
./deploy.sh frontend  # Frontend only (alias: fe, f)
./deploy.sh backend   # Backend only (alias: be, b)
```

---

## Part 3: Bug Fixes

### Fixed Route Ordering in analysis.py
**Problem:** `/api/analysis/project/{project_id}` was returning 404
**Cause:** Route defined after `/{analysis_id}`, so FastAPI matched "project" as an analysis_id
**Fix:** Moved `/project/{project_id}` route to top of router

### Fixed API URL in deploy.sh
**Problem:** SSL certificate error - cert is for `www.legacytocloud.com` only
**Fix:** Changed API URL from `https://legacytocloud.com/api` to `https://www.legacytocloud.com/api`

### Fixed Apache SPA Routing
**Problem:** Direct links to `/dashboard/projects/{id}` returned 404
**Cause:** Static export only generates `/dashboard/projects/index.html`
**Fix:** Added Apache rewrite rule:

```apache
# In /etc/apache2/sites-available/legacytocloud.com.conf
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule ^/dashboard/projects/.+ /dashboard/projects/index.html [L]
```

Also added `.htaccess` in `/www/dashboard/projects/`:
```
RewriteEngine On
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule .* index.html [L]
```

---

## Part 4: Schema Upload Feature

### New User Flow
Users can now analyze schemas without providing database credentials:

1. Go to project page
2. Choose "Upload Schema File" tab
3. Upload .sql file with CREATE TABLE statements
4. View parsed tables, columns, risks
5. Download Snowflake DDL

### Backend Files Created

#### `backend/app/services/sql_parser.py`
Parses MySQL CREATE TABLE statements from .sql files:
- Extracts table names, columns, types, constraints
- Detects primary keys and indexes
- Identifies migration risks (ENUM, SET, BLOB, no PK)
- Auto-detects SQL dialect (MySQL, PostgreSQL, MSSQL)

#### `backend/app/services/ddl_generator.py`
Generates Snowflake DDL from parsed schema:

**Type Mappings:**
| MySQL Type | Snowflake Type |
|------------|----------------|
| TINYINT | SMALLINT |
| SMALLINT | SMALLINT |
| MEDIUMINT | INTEGER |
| INT | INTEGER |
| BIGINT | BIGINT |
| FLOAT | FLOAT |
| DOUBLE | DOUBLE |
| DECIMAL(p,s) | NUMBER(p,s) |
| CHAR(n) | CHAR(n) |
| VARCHAR(n) | VARCHAR(n) |
| TEXT | VARCHAR(16777216) |
| BLOB | BINARY |
| DATE | DATE |
| TIME | TIME |
| DATETIME | TIMESTAMP_NTZ |
| TIMESTAMP | TIMESTAMP_NTZ |
| YEAR | SMALLINT |
| BOOLEAN | BOOLEAN |
| TINYINT(1) | BOOLEAN |
| JSON | VARIANT |
| ENUM | VARCHAR(255) |
| SET | VARCHAR(1024) |

**Generated DDL includes:**
- CREATE SCHEMA statement
- CREATE TABLE statements with proper types
- NOT NULL constraints
- DEFAULT values
- PRIMARY KEY constraints
- Comments
- Clustering key recommendations (from indexes)

#### `backend/app/api/analysis.py` - New Endpoint
```python
@router.post("/upload")
async def upload_schema(
    file: UploadFile,
    dialect: Optional[str] = None,
    current_user: User = Depends(get_current_user)
)
```
- Accepts .sql file upload
- Validates file type and content
- Parses SQL and generates Snowflake DDL
- Returns same format as quick analysis

### Frontend Changes

#### `frontend/src/lib/api.ts`
Added upload method:
```typescript
analysis.upload(file: File, dialect?: string): Promise<AnalysisResult>
```

Added `snowflake_ddl` field to `AnalysisResult` interface.

#### `frontend/src/app/dashboard/projects/[[...slug]]/client.tsx`
- Added tabs: "Connect to Database" / "Upload Schema File"
- File upload UI with drag & drop
- File validation (.sql only)
- Shows file name and size
- Helper text with mysqldump command

**DDL Display:**
- Preview button with syntax-highlighted code view
- Copy to clipboard button
- Download as .sql file button

---

## Files Modified/Created

### Created
- `frontend/src/app/mariadb-to-snowflake/page.tsx`
- `frontend/src/app/aurora-to-snowflake/page.tsx`
- `backend/app/services/sql_parser.py`
- `backend/app/services/ddl_generator.py`

### Modified
- `deploy.sh` - Added flexible deploy options
- `config/apache/legacytocloud-prod.conf` - Added SPA rewrite rules
- `backend/app/api/analysis.py` - Fixed route order, added upload endpoint
- `backend/app/schemas/analysis.py` - Added snowflake_ddl field
- `frontend/src/lib/api.ts` - Added upload method, updated types
- `frontend/src/app/dashboard/projects/[[...slug]]/client.tsx` - Added upload UI
- Footer navigation on all migration pages

---

## Deploy Commands

```bash
cd /usr/local/www/legacytocloud.com
git pull
./deploy.sh

# Update Apache config
sudo cp config/apache/legacytocloud-prod.conf /etc/apache2/sites-available/legacytocloud.com.conf
sudo systemctl reload apache2
```

---

## Test Schema Upload

1. Export your schema: `mysqldump --no-data mydb > schema.sql`
2. Go to project page
3. Click "Upload Schema File" tab
4. Select your .sql file
5. Click "Analyze Schema File"
6. View results and download Snowflake DDL
